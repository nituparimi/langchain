Before running locallama.py

Download Ollama

ollama run modelname

example: ollama run gemma or ollama run llama2
